{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximizing traffic to your Hacker News Posts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look into the different posts on Hacker News and how time and type affect viewings and comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know the feeling, we all do!  The rush and anxiety of posting something, then checking every few minutes to see if there are responses.  You may see posts that get a lot of attention and you are unsure why, or you may see posts that receive no attention that definitely deserve some, and you may ask yourself, why?  Are there factors other than subject matter that affect the traffic a certain post gets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we are going to compare posts made on Ask HN and Show HN and see if posting at certain times leads to more comments.\n",
    "\n",
    "To start let's import our modules and open our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports modules \n",
    "from csv import reader\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16'],\n",
       " ['12578979',\n",
       "  'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake',\n",
       "  'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94',\n",
       "  '1',\n",
       "  '0',\n",
       "  'markgainor1',\n",
       "  '9/26/2016 3:14']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opens csv files and turns them into a list of lists for analysis\n",
    "open_file = open('HN_posts_year_to_Sep_26_2016.csv')\n",
    "read_file = reader(open_file)\n",
    "hn = list(read_file)\n",
    "hn_header = hn[0]\n",
    "hn = hn[1:]\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After taking a cursory look at our data, let's seperate our posts into 3 categories.  We want to look at posts on Ask HN and Show HN seperately, and sepereate every other post as thery will not be a part of this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n"
     ]
    }
   ],
   "source": [
    "# Creates empty lists to store relevant rows from our dataset\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "# loops through the dataset identifying different posts and appending them to the appropriate list\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    # the lower() operator takes the string and converts all letters to lower case so we do not have \n",
    "    # to worry about capital letters\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent!  Now that we have separated the Ask HN and Show HN posts, let's look at the average number of comments each post gets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments for ask HN posts is: 10.393478498741656\n",
      "The average number of comments for show HN posts is: 4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "# Sums the total number of comments for Ask HN posts\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4]) \n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "# Computes the average number of comments for Ask HN posts    \n",
    "ave_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print('The average number of comments for ask HN posts is:', ave_ask_comments)\n",
    "\n",
    "\n",
    "total_show_comments = 0\n",
    "\n",
    "# Sums the total number of comments for Show HN posts\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "# Computes the average number of comments on Show HN posts\n",
    "ave_show_comments = total_show_comments / len(show_posts)\n",
    "print('The average number of comments for show HN posts is:', ave_show_comments)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average the ask HN posts reviece 213% more comments than show HN posts.  This makes sense as ask posts are created to start a discussion while Show HN posts do not necessarily warrant a comment.  Due to Ask HN posts recieving a lot mroe traffic we will restrict the remainder of the analysis to Ask HN posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to know, will posting my question at a specific time garner more comments?\n",
    "\n",
    "To answer this let's create a 2 column data base that holds the date time the post was created and the number of comments it received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6], int(row[4])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates two dictionaries that allow us to build frequency tables, looking at number of posts per hour\n",
    "# and number of comments per hous\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = \"%m/%d/%Y %H:%M\" # this specifies the format the date time is written in to allow python to parse \n",
    "                               # through it and extract the necessary data\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    date = dt.datetime.strptime(date, date_format) \n",
    "    hour = date.strftime(\"%H\") # extracts the hour information from the date-time\n",
    "    # generates a frequency table based on post and comments made each hour\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have those two dictionaries let's calculate the average number of comments per post for every hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['02', 11.137546468401487],\n",
       " ['01', 7.407801418439717],\n",
       " ['22', 8.804177545691905],\n",
       " ['21', 8.687258687258687],\n",
       " ['19', 7.163043478260869],\n",
       " ['17', 9.449744463373083],\n",
       " ['15', 28.676470588235293],\n",
       " ['14', 9.692007797270955],\n",
       " ['13', 16.31756756756757],\n",
       " ['11', 8.96474358974359],\n",
       " ['10', 10.684397163120567],\n",
       " ['09', 6.653153153153153],\n",
       " ['07', 7.013274336283186],\n",
       " ['03', 7.948339483394834],\n",
       " ['23', 6.696793002915452],\n",
       " ['20', 8.749019607843136],\n",
       " ['16', 7.713298791018998],\n",
       " ['08', 9.190661478599221],\n",
       " ['00', 7.5647840531561465],\n",
       " ['18', 7.94299674267101],\n",
       " ['12', 12.380116959064328],\n",
       " ['04', 9.7119341563786],\n",
       " ['06', 6.782051282051282],\n",
       " ['05', 8.794258373205741]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_comments_hour = []\n",
    "# uses our frequency tables to compute the average comments per post every hour\n",
    "for hour in counts_by_hour:\n",
    "    ave_comments_hour.append([hour, comments_by_hour[hour] / counts_by_hour[hour]])\n",
    "    \n",
    "ave_comments_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!  But to improve readability let's sort this by highest average comments to see which times of the day get the highest amount of comments.\n",
    "First let's switch the columns so that we can sort by average number of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11.137546468401487, '02'],\n",
       " [7.407801418439717, '01'],\n",
       " [8.804177545691905, '22'],\n",
       " [8.687258687258687, '21'],\n",
       " [7.163043478260869, '19'],\n",
       " [9.449744463373083, '17'],\n",
       " [28.676470588235293, '15'],\n",
       " [9.692007797270955, '14'],\n",
       " [16.31756756756757, '13'],\n",
       " [8.96474358974359, '11'],\n",
       " [10.684397163120567, '10'],\n",
       " [6.653153153153153, '09'],\n",
       " [7.013274336283186, '07'],\n",
       " [7.948339483394834, '03'],\n",
       " [6.696793002915452, '23'],\n",
       " [8.749019607843136, '20'],\n",
       " [7.713298791018998, '16'],\n",
       " [9.190661478599221, '08'],\n",
       " [7.5647840531561465, '00'],\n",
       " [7.94299674267101, '18'],\n",
       " [12.380116959064328, '12'],\n",
       " [9.7119341563786, '04'],\n",
       " [6.782051282051282, '06'],\n",
       " [8.794258373205741, '05']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_ave_hour = []\n",
    "\n",
    "for row in ave_comments_hour:\n",
    "    swap_ave_hour.append([row[1], row[0]]) # switches the columns\n",
    "swap_ave_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28.676470588235293, '15'],\n",
       " [16.31756756756757, '13'],\n",
       " [12.380116959064328, '12'],\n",
       " [11.137546468401487, '02'],\n",
       " [10.684397163120567, '10'],\n",
       " [9.7119341563786, '04'],\n",
       " [9.692007797270955, '14'],\n",
       " [9.449744463373083, '17'],\n",
       " [9.190661478599221, '08'],\n",
       " [8.96474358974359, '11'],\n",
       " [8.804177545691905, '22'],\n",
       " [8.794258373205741, '05'],\n",
       " [8.749019607843136, '20'],\n",
       " [8.687258687258687, '21'],\n",
       " [7.948339483394834, '03'],\n",
       " [7.94299674267101, '18'],\n",
       " [7.713298791018998, '16'],\n",
       " [7.5647840531561465, '00'],\n",
       " [7.407801418439717, '01'],\n",
       " [7.163043478260869, '19'],\n",
       " [7.013274336283186, '07'],\n",
       " [6.782051282051282, '06'],\n",
       " [6.696793002915452, '23'],\n",
       " [6.653153153153153, '09']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this sorts our average number of comments in descending order\n",
    "sorted_swap = sorted(swap_ave_hour, reverse = True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Now that we have sorted our list, let's print out our top 5 results in a more readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00 : 28.68\n",
      "13:00 : 16.32\n",
      "12:00 : 12.38\n",
      "02:00 : 11.14\n",
      "10:00 : 10.68\n"
     ]
    }
   ],
   "source": [
    "# This loop prints out our results in a hour : average posts format so we can easily see the times \n",
    "# when we get the highest average comments\n",
    "for i in range(0,5):\n",
    "    num, hour = sorted_swap[i][0], sorted_swap[i][1] \n",
    "    hour = dt.datetime.strptime(str(hour), \"%H\")\n",
    "    hour = hour.strftime(\"%H\")\n",
    "    print(\"{hour}:00 : {num:.2f}\".format(hour = hour, num = num))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, posting in Ask HN in the afternoon (specifically 3pm or 1pm) will get you on average the highest number of comments for your post.  So be strategic with the time of day that you are asking Hacker News and happy posting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
